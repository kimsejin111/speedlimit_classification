{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speedlimits.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNJe5uImLGHKEdjm/8Ly/wg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimsejin111/speedlimit_classification/blob/main/speedlimits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0MJryXcE0rx"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import time\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
        "import pathlib"
      ],
      "metadata": {
        "id": "Nt3JhKd7HZWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir='/content/gdrive/MyDrive/data'"
      ],
      "metadata": {
        "id": "f6ye8TkcHGy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir=pathlib.Path(data_dir)\n",
        "\n",
        "batch_size=32\n",
        "image_height=180\n",
        "image_width=180\n",
        "\n",
        "d_image_count = len(list(data_dir.glob('*/*.png')))\n",
        "print(d_image_count)\n"
      ],
      "metadata": {
        "id": "34cci34UIULS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds=tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2, # 왜 0.2로 하는거지?\n",
        "    subset=\"training\",\n",
        "    seed=123,   # seed는 무얼 의미하는 거지?\n",
        "    image_size=(image_height, image_width),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "val_ds=tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(image_height, image_width),\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "kiBjpgvJJGId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_ds.class_names\n",
        "plt.figure(figsize=(10,10))\n",
        "for images, labels in train_ds.take(1): #take 함수는 무슨 함수일까\n",
        "    for i in range(9):\n",
        "        ax=plt.subplot(3,3,i+1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\")) #numpy,imshow 는 무슨 함수일까\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UzACWku5aR0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE =tf.data.experimental.AUTOTUNE\n",
        "train_ds=train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds=val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "BQFDjujZbCfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normaliztion_layer= layers.experimental.preprocessing.Rescaling(1./255)\n",
        "\n",
        "normalized_ds=train_ds.map(lambda x,y:(normaliztion_layer(x),y))\n",
        "image_batch,labels_batch = next(iter(normalized_ds)) #자동 반복 함수\n",
        "first_image = image_batch[0]\n",
        "print(np.min(first_image), np.max(first_image))"
      ],
      "metadata": {
        "id": "cwZqVzVybPBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.experimental.preprocessing.RandomFlip(\n",
        "            \"horizontal\",\n",
        "            input_shape=(\n",
        "                image_height,\n",
        "                image_width,\n",
        "                3)),\n",
        "        layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "        layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "sSFmsfdbbje5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes=5\n",
        "\n",
        "model2 =Sequential([\n",
        "    layers.experimental.preprocessing.Rescaling(1. / 255, input_shape=(image_height, image_width, 3)),\n",
        "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPool2D(),\n",
        "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPool2D(),\n",
        "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPool2D(),  # Pooling 필터링 개념으로 생각하자  해당 convolution에서 MAX값으로 필터링 하여 데이터 크기를 줄임\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Flatten(),  # convolution의 dimension을 줄여주는 함수\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(num_classes)\n",
        "])"
      ],
      "metadata": {
        "id": "rIKe8AZcbyZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4PJKyRCycevA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "zpKTY-_ZcBCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=15\n",
        "history=model2.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs,\n",
        ")"
      ],
      "metadata": {
        "id": "s4s0pj4DcFrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_E=history.history['accuracy']\n",
        "val_E_acc=history.history['val_accuracy']\n",
        "\n",
        "loss_E=history.history['loss']\n",
        "val_E_loss=history.history['val_loss']\n",
        "\n",
        "epochs_range= range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs_range,acc_E,label=\"Training ACC\")\n",
        "plt.plot(epochs_range,val_E_acc,label=\"Validation ACC\")\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs_range,loss_E,label=\"Training Loss\")\n",
        "plt.plot(epochs_range,val_E_loss,label=\"Validation Loss\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8NyVGEaxcMQW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}